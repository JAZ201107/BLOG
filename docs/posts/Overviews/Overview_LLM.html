<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-10-25">
<meta name="description" content="This is an overview of the Muultimodal Large Language Models. It includes the defintion of the large language models, the multimodal large language models, and the applications of those models. Besides, it also includes to fine-tune those models with different methods like LoRA.">

<title>Overview: Large Language Models – Yuyang’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Overview: Large Language Models – Yuyang’s Blog">
<meta property="og:description" content="This is an overview of the Muultimodal Large Language Models. It includes the defintion of the large language models, the multimodal large language models, and the applications of those models. Besides, it also includes to fine-tune those models with different methods like LoRA.">
<meta property="og:image" content="Images/OverviewOfMLLM.png">
<meta property="og:site_name" content="Yuyang's Blog">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Yuyang’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/JAZ201107"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhang-yuyang/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#what-is-the-large-language-model" id="toc-what-is-the-large-language-model" class="nav-link active" data-scroll-target="#what-is-the-large-language-model">What is the Large Language Model</a></li>
  <li><a href="#pre-training" id="toc-pre-training" class="nav-link" data-scroll-target="#pre-training">Pre-Training</a>
  <ul class="collapse">
  <li><a href="#model" id="toc-model" class="nav-link" data-scroll-target="#model">Model</a>
  <ul class="collapse">
  <li><a href="#architecture" id="toc-architecture" class="nav-link" data-scroll-target="#architecture">Architecture</a></li>
  <li><a href="#normalization" id="toc-normalization" class="nav-link" data-scroll-target="#normalization">Normalization</a></li>
  <li><a href="#activation-functions" id="toc-activation-functions" class="nav-link" data-scroll-target="#activation-functions">Activation Functions</a></li>
  <li><a href="#position-embeddings" id="toc-position-embeddings" class="nav-link" data-scroll-target="#position-embeddings">Position Embeddings</a></li>
  <li><a href="#attention" id="toc-attention" class="nav-link" data-scroll-target="#attention">Attention</a></li>
  </ul></li>
  <li><a href="#loss-functions" id="toc-loss-functions" class="nav-link" data-scroll-target="#loss-functions">Loss Functions</a></li>
  <li><a href="#optimizers" id="toc-optimizers" class="nav-link" data-scroll-target="#optimizers">Optimizers</a>
  <ul class="collapse">
  <li><a href="#learning-rate-scheduler" id="toc-learning-rate-scheduler" class="nav-link" data-scroll-target="#learning-rate-scheduler">Learning Rate Scheduler</a></li>
  <li><a href="#gradient-clip-and-weight-decay" id="toc-gradient-clip-and-weight-decay" class="nav-link" data-scroll-target="#gradient-clip-and-weight-decay">Gradient Clip and Weight Decay</a></li>
  </ul></li>
  <li><a href="#training-process" id="toc-training-process" class="nav-link" data-scroll-target="#training-process">Training Process</a></li>
  </ul></li>
  <li><a href="#post-training" id="toc-post-training" class="nav-link" data-scroll-target="#post-training">Post-Training</a>
  <ul class="collapse">
  <li><a href="#formatted-instance-construction" id="toc-formatted-instance-construction" class="nav-link" data-scroll-target="#formatted-instance-construction">Formatted Instance Construction</a></li>
  <li><a href="#alignment-tuning" id="toc-alignment-tuning" class="nav-link" data-scroll-target="#alignment-tuning">Alignment Tuning</a></li>
  <li><a href="#parameter-efficient-model-adaption" id="toc-parameter-efficient-model-adaption" class="nav-link" data-scroll-target="#parameter-efficient-model-adaption">Parameter-Efficient Model Adaption</a>
  <ul class="collapse">
  <li><a href="#adapter-tuning" id="toc-adapter-tuning" class="nav-link" data-scroll-target="#adapter-tuning">Adapter Tuning</a></li>
  <li><a href="#prefix-tuning" id="toc-prefix-tuning" class="nav-link" data-scroll-target="#prefix-tuning">Prefix Tuning</a></li>
  <li><a href="#prompt-tuning" id="toc-prompt-tuning" class="nav-link" data-scroll-target="#prompt-tuning">Prompt Tuning</a></li>
  <li><a href="#low-rank-adaptationlora" id="toc-low-rank-adaptationlora" class="nav-link" data-scroll-target="#low-rank-adaptationlora">Low-Rank Adaptation(LoRA)</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#utilization" id="toc-utilization" class="nav-link" data-scroll-target="#utilization">Utilization</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Overview: Large Language Models</h1>
  <div class="quarto-categories">
    <div class="quarto-category">LLM</div>
    <div class="quarto-category">Overview</div>
  </div>
  </div>

<div>
  <div class="description">
    This is an overview of the Muultimodal Large Language Models. It includes the defintion of the large language models, the multimodal large language models, and the applications of those models. Besides, it also includes to fine-tune those models with different methods like LoRA.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2024-10-25</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Last modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">2024-12-02</p>
    </div>
  </div>
    
  </div>
  


</header>


<p><img src="images/Multimodel Large Language Model.png" class="img-fluid"></p>
<section id="what-is-the-large-language-model" class="level1">
<h1>What is the Large Language Model</h1>
<p>Large Language Model, as the name, is the Language Model that with Large Training Dataset, Large number of parameters. When the research scale the language model, there are some abilities that are not present in small models emerge in the Large Language Model. Below are three typical emergent abilities for LLMs: 1. <strong>In-Context Learning</strong>: When the LLM is provided with - Natural Language instruction - Several Task Demonstrations It can generate the expected output of input text without requiring additional training or weight update. 2. <strong>Instruction Following</strong>: With the instruction tuning, the model can respond accurately based on the user’s instructions or prompt. The model tries to understand what the user wants and generates an appropriate answer. 3. <strong>Step-By-Step reasoning</strong>: With chain-of-thought(CoT) prompting strategy, LLM can solve the complex task, (e.g.&nbsp;mathematical problem) by utilizing the prompting mechanism that involves intermediate reasoning steps.</p>
<p>During the development of the LLMs, there are also several important techniques that lead to the success of LLMs: - <strong>Scaling</strong>: By scaling the model size and training data, the model can get better performance according to the scaling law. - <strong>Distributed Training</strong>: Due to the huge model size and datasets, it is very hard to fit the model into the single computer. The Distributed training algorithms are needed to train the model. - <strong>Ability Eliciting</strong>: Design a set of suitable task instruction or specific in-context-learning strategies to elicit potential power of LLM. - <strong>Alignment Tuning</strong>: Align the LLM with human values(preference), LLM can avoid to generate toxic, biased or even harmful content for humans. With technique such as reinforcement learning with human feedback to align the model, which shows a strong alignment capacity in producing high-quality, harmless responses - <strong>Tools manipulation</strong>: LLM can generate pure text, however, in some tasks, the output are hardly to express as the pure text. To solve this problem, we can employ external tools to compensate for the deficiencies of LLMs.</p>
<p>The basic training process of LLM can be divided into three parts: - Pre-Training: get the general and essential language understanding and generation skills. - Post-Training: The pre-trained LLM is general, it might perform good on some specific task, so, we need to fine-tuning the LLM to exploit the potential - Utilization: After</p>
</section>
<section id="pre-training" class="level1">
<h1>Pre-Training</h1>
<p>To train a neural network, we four essential components - Dataset - Model - Loss Function - Optimizer Same as the training of the LLM. Now I break those parts: ## Dataset The LLMs have a strong demand for high-quality data for model training. There are many text on the Internet, which can be broadly categorized into two types: - General data: The General data are crawled from the Internet, it includes such as webpages, books, and conversational text, which provide a variety of topics and context - Specialized Data: Those datasets are useful to improve the specific capabilities of LLMs on downstream tasks. For example, Multi-lingual text, Code</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202163003.png" class="img-fluid figure-img"></p>
<figcaption>image.png</figcaption>
</figure>
</div>
<p>After we have the “raw” dataset, we need to filter the dataset to constructing the pre-training corpus and removing noisy, redundant, irrelevant and toxic data. The basic steps are: - Filtering and Selection. Using the classifier-based and heuristic-based approach to remove the low-quality data from the collected corpus. The classifier-based methods is to train an selection classifier based on the high quality text and leverages it to identify and filter out low-quality data. The heuristic-based approach can be filter the text through a set of well-designed rules, for example - Language based filtering: only keep the English words and filter other languages - Metric based filtering: Evaluating metrics(e.g.&nbsp;perplexity) can be employed to detect and remove unnatural sentences - Keyword based filtering: Based on the specific keyword, some noisy or un-useful element in the text can be moved. - De-duplication: the duplicate data in a corpus would reduce the diversity of language models. The de-duplication can be performed at different granularities: - Sentence-level - Document-Level - Dataset-Level - Privacy Reduction: Because the LLMs will be deploy in practice, it is necessary to remove the personally identifiable information(PII) from the pre-training corpus. It can achieve by rule-based methods - Tokenization: The final step is to convert the pure text into some model can understand. Tokenization is a method map word or sub-word to a number - Byte-Pair Encoding(BPE) tokenization. - WordPiece Tokenization - Unigram Tokenization</p>
<p>After data pre-processing, we got the clean dataset, the next step it to design strategies to schedule the multi-source data. Two important aspects should be paid attention:] - Data Mixture: the proportion of each data source - Data Curriculum: The order in which each data source is scheduled for training</p>
<section id="model" class="level2">
<h2 class="anchored" data-anchor-id="model">Model</h2>
<section id="architecture" class="level3">
<h3 class="anchored" data-anchor-id="architecture">Architecture</h3>
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202163311.png" class="img-fluid" alt="image.png"> The mainstream architecture of existing LLMs can be cateogorized into three types: - Causal Decoder: This model is the most adopted architecture of LLMs - Prefix Decoder: This model enable performing bidirectional attention over the prefix tokens and un-directional attention on generated tokens. - Encoder-Decoder: This is the classic transformer model architecture,</p>
<p>Besides those three architectures, there are also some other architecture: - Mixture of Experts: A subset of NN weights for each input are sparsely activated - Parameterized State Space Models: Can be view as a combination of RNN and CNN. - Mamba: It aims to selectively filter out or remember information during state update.</p>
</section>
<section id="normalization" class="level3">
<h3 class="anchored" data-anchor-id="normalization">Normalization</h3>
<p>Normalization is a strategy to stablized the training of the NN. - Layer Norm: used in the classic Transformer, it can - RMSNorm: Similiar as the layer norm except only one trainable parameter, which is faster than the LayerNrom - DeepNorm: Using the Deep Norm for the deep transformers, and as residual connections, the transformer can scaled up to 1.000 layers</p>
<p>The position of the normalization is also play a crucial role in the LLMs.</p>
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202164713.png" class="img-fluid" alt="image.png"> - Post-LN: used in the vanilla transformers, which is placed between residual blocks. However, existing work has found that the training of Transformers with post-LN tends to be instable due to the large gradients near the output layer - Pre-LN: Applied before each sub-layer. The Transformers with pre-LN are more stable in training. - Sandwich-LN. Add an extra LN before the residual connections to avoid the value explosiion issues in Transformer layers, it may lead to collapse of training</p>
</section>
<section id="activation-functions" class="level3">
<h3 class="anchored" data-anchor-id="activation-functions">Activation Functions</h3>
<ul>
<li>GeLU are widely used</li>
<li>The variants of GLU such as: SwiGLU and GeGLU, perform better but require extra parameters in the FF networks</li>
</ul>
</section>
<section id="position-embeddings" class="level3">
<h3 class="anchored" data-anchor-id="position-embeddings">Position Embeddings</h3>
<ul>
<li>Absolute position. embedding: the vanilla transformer, it adapted sinusoidal positional embedding, another is learned position embeddings</li>
<li>Relative Position embedding: relative positional embeddings are generated according to the offsets between keys and queries.The calculation of attention scores between keys and queries has been modified to introduce learnable embeddings corresponding to relative positions</li>
<li>Rotary Position Embedding: sets specific rotatory matrices based on the absolute position of each key or query.</li>
</ul>
</section>
<section id="attention" class="level3">
<h3 class="anchored" data-anchor-id="attention">Attention</h3>
<ul>
<li>Full Attention: scaled dot product attention, multi-head attention</li>
<li>Sparse Attention: The full attention is quadratic computational complexity, there are several sparse attention being proposed to speed up the traing. For example:
<ul>
<li>Locally banded sparse attention</li>
</ul></li>
<li>Multi-query / grouped-query attention: different heads share the same linear transformation matrices on the keys and values. It can achieve high inference speed</li>
<li>Flash Attention: This attention is not a new attention mechinism, but a way to optimize the speed and memory comsumption of the attention modules on GPUs from an IO-aware perspective.</li>
<li>Paged Attention: improved the memory efficiency and throughput of deployed LLMs</li>
</ul>
</section>
</section>
<section id="loss-functions" class="level2">
<h2 class="anchored" data-anchor-id="loss-functions">Loss Functions</h2>
<p>Different loss function means we have different training objects: ### Language Modeling <span class="math display">\[
\mathcal{L}_{\text{LM}}(\mathrm{x}) = \sum_{i=1}^{n}\log P(x_{i} | \mathrm{x}_{ &lt; i})
\]</span></p>
<p>The <strong>Cross Entropy Loss</strong> is the most common loss function used to pre-train decoder-only LLM, such as GPT2 and PaLM.</p>
</section>
<section id="optimizers" class="level2">
<h2 class="anchored" data-anchor-id="optimizers">Optimizers</h2>
<p>The most common used optimizer are: - Adam - AdamW which are widely utilized from training LLMs with adaptive estimated of lower-order moments for first-order gradient-based optimization.,</p>
<ul>
<li>Adafactor</li>
</ul>
<section id="learning-rate-scheduler" class="level3">
<h3 class="anchored" data-anchor-id="learning-rate-scheduler">Learning Rate Scheduler</h3>
<p>learning rate is also important during the training. Existing LLMs usually adopt a similar learning rate schedule with the warm-up and decay strategies during pre-training.</p>
</section>
<section id="gradient-clip-and-weight-decay" class="level3">
<h3 class="anchored" data-anchor-id="gradient-clip-and-weight-decay">Gradient Clip and Weight Decay</h3>
<p>commonly set the threshold of gradient clipping to 1.0 and weight decay rate to 0.1.</p>
</section>
</section>
<section id="training-process" class="level2">
<h2 class="anchored" data-anchor-id="training-process">Training Process</h2>
<p>As the model and data sizes increase, it has become challenging to efficiently train LLMs under a limited computational resource. - Data Parallelism: one of the most fundamental approaches to improving the training throughput - Pipeline Parallelism: distribute the different layers of a LLM into multiple GPUs. - Tensor Parallelism: tensor parallelism focuses on decomposing the tensors (the parameter matrices) of LLMs.</p>
<p>Besides the paraleelism, Mixed Precision Training is also a useful strategy for training.</p>
</section>
</section>
<section id="post-training" class="level1">
<h1>Post-Training</h1>
<p>After the pre-training, the LLMs have acquired the general abilities for solving various tasks. However, the LLM’s abilities can be further adapted according to specific goal, which leads us to the post-training. There are two main approaches for post training: - Instruction Tuning: Enhance the abilities of LLMs. - Alignment Tuning: Align the behaviours of LLMs with human values or preference ## Instruction Tuning Instruction tuning is the approach to fine-tuning pre-trained LLMs on a collection of formatted instances in the form of natural language, it is highly related to: - Supervised Fine-Tuning - Multi-Task prompted training We first need to collect or construct instruction-formatted instances. Then, we employ these formatted instances to fine-tune LLMs in a supervised learning way</p>
<section id="formatted-instance-construction" class="level3">
<h3 class="anchored" data-anchor-id="formatted-instance-construction">Formatted Instance Construction</h3>
<p>An instruction-formatted instance consists of: - Task Description(instruction) - An input - The correspoinding output (optional) - A small number of demonstrations (optional)</p>
</section>
<section id="alignment-tuning" class="level2">
<h2 class="anchored" data-anchor-id="alignment-tuning">Alignment Tuning</h2>
</section>
<section id="parameter-efficient-model-adaption" class="level2">
<h2 class="anchored" data-anchor-id="parameter-efficient-model-adaption">Parameter-Efficient Model Adaption</h2>
<p>Because the LLMs consist of a huge amount of model parameters, it would be costly to perform the fullparameter tuning. So, the Parameter-Efficient Model Adaption can be conducted to tuning the model.</p>
<section id="adapter-tuning" class="level3">
<h3 class="anchored" data-anchor-id="adapter-tuning">Adapter Tuning</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202173232.png" class="img-fluid figure-img"></p>
<figcaption>image.png</figcaption>
</figure>
</div>
<p>Incorporates small network modules(adapter) into the Transformer model. During the fine-tuning, the original weight are frozen, while the parameter in the adapter will be optimized according to the specific task goals.</p>
</section>
<section id="prefix-tuning" class="level3">
<h3 class="anchored" data-anchor-id="prefix-tuning">Prefix Tuning</h3>
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202173441.png" class="img-fluid" alt="image.png"> Prefix tuning prepends a sequence of prefixes, which are a set of trainable continuous vectors, to each Transformer layer in language models.Prefix tuning prepends a sequence of prefixes, which are a set of trainable continuous vectors, to each Transformer layer in language models.</p>
</section>
<section id="prompt-tuning" class="level3">
<h3 class="anchored" data-anchor-id="prompt-tuning">Prompt Tuning</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202173606.png" class="img-fluid figure-img"></p>
<figcaption>image.png</figcaption>
</figure>
</div>
<p>Different from prefix tuning, prompt tuning mainly focuses on incorporating trainable prompt vectors at the input layer3</p>
</section>
<section id="low-rank-adaptationlora" class="level3">
<h3 class="anchored" data-anchor-id="low-rank-adaptationlora">Low-Rank Adaptation(LoRA)</h3>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="https://noblecatt-1304922865.cos.ap-singapore.myqcloud.com/20241202173657.png" class="img-fluid figure-img"></p>
<figcaption>image.png</figcaption>
</figure>
</div>
<section id="q-lora" class="level4">
<h4 class="anchored" data-anchor-id="q-lora">Q-LoRA</h4>
</section>
</section>
</section>
</section>
<section id="utilization" class="level1">
<h1>Utilization</h1>
<p>After Post-Training, a major approach to using LLMs is to design suitable prompting strategies for solving various tasks.</p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>