<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="dcterms.date" content="2024-10-25">
<meta name="description" content="This is an overview of the Deep Reinforcement Learning. It includes the defintion of the deep reinforcement learning, some popular algorithms for example deep Q learning and variants, policy gradient methods and actor-critic methods for example A3C, DDPG, and PPO. Besides, it also includes the applications of those models.">

<title>Overview: Deep Reinforcement Learning – Yuyang’s Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-text-highlighting-styles">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-dark.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" class="quarto-color-scheme" id="quarto-bootstrap" data-mode="light">
<link href="../../site_libs/bootstrap/bootstrap-dark.min.css" rel="prefetch" class="quarto-color-scheme quarto-color-alternate" id="quarto-bootstrap" data-mode="dark">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
<meta property="og:title" content="Overview: Deep Reinforcement Learning – Yuyang’s Blog">
<meta property="og:description" content="This is an overview of the Deep Reinforcement Learning. It includes the defintion of the deep reinforcement learning, some popular algorithms for example deep Q learning and variants, policy gradient methods and actor-critic methods for example A3C, DDPG, and PPO. Besides, it also includes the applications of those models.">
<meta property="og:image" content="Images/Overview_DRL.png">
<meta property="og:site_name" content="Yuyang's Blog">
</head>

<body class="floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">Yuyang’s Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/JAZ201107"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://www.linkedin.com/in/zhang-yuyang/"> <i class="bi bi-linkedin" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
  <a href="" class="quarto-color-scheme-toggle quarto-navigation-tool  px-1" onclick="window.quartoToggleColorScheme(); return false;" title="Toggle dark mode"><i class="bi"></i></a>
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <nav id="TOC" role="doc-toc" class="toc-active" data-toc-expanded="1">
    <h2 id="toc-title">Contents</h2>
   
  <ul>
  <li><a href="#key-concepts-and-notations" id="toc-key-concepts-and-notations" class="nav-link active" data-scroll-target="#key-concepts-and-notations">Key Concepts and Notations</a></li>
  <li><a href="#q-learning-and-variants" id="toc-q-learning-and-variants" class="nav-link" data-scroll-target="#q-learning-and-variants">Q-Learning and Variants</a>
  <ul class="collapse">
  <li><a href="#classical-deepq-learning" id="toc-classical-deepq-learning" class="nav-link" data-scroll-target="#classical-deepq-learning">Classical (Deep)Q-Learning</a></li>
  <li><a href="#double-deep-q-learning" id="toc-double-deep-q-learning" class="nav-link" data-scroll-target="#double-deep-q-learning">Double (Deep) Q-Learning</a></li>
  <li><a href="#dueling-dqn" id="toc-dueling-dqn" class="nav-link" data-scroll-target="#dueling-dqn">Dueling DQN</a></li>
  <li><a href="#noisy-q-learning" id="toc-noisy-q-learning" class="nav-link" data-scroll-target="#noisy-q-learning">Noisy Q-Learning</a></li>
  <li><a href="#soft-q-learning" id="toc-soft-q-learning" class="nav-link" data-scroll-target="#soft-q-learning">Soft Q-Learning</a></li>
  <li><a href="#experience-replay-buffer" id="toc-experience-replay-buffer" class="nav-link" data-scroll-target="#experience-replay-buffer">Experience Replay Buffer</a></li>
  <li><a href="#section" id="toc-section" class="nav-link" data-scroll-target="#section"></a></li>
  </ul></li>
  <li><a href="#policy-based-algorithm" id="toc-policy-based-algorithm" class="nav-link" data-scroll-target="#policy-based-algorithm">Policy Based Algorithm</a>
  <ul class="collapse">
  <li><a href="#reinforce" id="toc-reinforce" class="nav-link" data-scroll-target="#reinforce">REINFORCE</a></li>
  <li><a href="#actor-critic-methods" id="toc-actor-critic-methods" class="nav-link" data-scroll-target="#actor-critic-methods">Actor-Critic Methods</a>
  <ul class="collapse">
  <li><a href="#basic-actor-critic-algorithm" id="toc-basic-actor-critic-algorithm" class="nav-link" data-scroll-target="#basic-actor-critic-algorithm">Basic Actor-Critic Algorithm</a></li>
  <li><a href="#advantage-actor-critic-algorithm" id="toc-advantage-actor-critic-algorithm" class="nav-link" data-scroll-target="#advantage-actor-critic-algorithm">Advantage Actor-Critic Algorithm</a></li>
  <li><a href="#asyn-advantage-actor-critic-algorithm-a3d" id="toc-asyn-advantage-actor-critic-algorithm-a3d" class="nav-link" data-scroll-target="#asyn-advantage-actor-critic-algorithm-a3d">Asyn Advantage Actor-Critic Algorithm (A3D)</a></li>
  </ul></li>
  <li><a href="#trust-region-policy-optimization" id="toc-trust-region-policy-optimization" class="nav-link" data-scroll-target="#trust-region-policy-optimization">Trust Region Policy Optimization</a></li>
  <li><a href="#proximal-policy-optimization" id="toc-proximal-policy-optimization" class="nav-link" data-scroll-target="#proximal-policy-optimization">Proximal Policy Optimization</a></li>
  </ul></li>
  <li><a href="#inverse-reinforcement-learning" id="toc-inverse-reinforcement-learning" class="nav-link" data-scroll-target="#inverse-reinforcement-learning">Inverse Reinforcement Learning</a></li>
  <li><a href="#meta-reinforcement-learning" id="toc-meta-reinforcement-learning" class="nav-link" data-scroll-target="#meta-reinforcement-learning">Meta Reinforcement Learning</a></li>
  <li><a href="#reinforcement-learning-and-inference" id="toc-reinforcement-learning-and-inference" class="nav-link" data-scroll-target="#reinforcement-learning-and-inference">Reinforcement Learning and Inference</a></li>
  <li><a href="#reinforcement-learning-with-sequence-models" id="toc-reinforcement-learning-with-sequence-models" class="nav-link" data-scroll-target="#reinforcement-learning-with-sequence-models">Reinforcement Learning with Sequence Models</a></li>
  <li><a href="#reference" id="toc-reference" class="nav-link" data-scroll-target="#reference">Reference</a></li>
  </ul>
</nav>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar zindex-bottom">
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Overview: Deep Reinforcement Learning</h1>
  <div class="quarto-categories">
    <div class="quarto-category">Reinforcement Learning</div>
    <div class="quarto-category">Overview</div>
  </div>
  </div>

<div>
  <div class="description">
    This is an overview of the Deep Reinforcement Learning. It includes the defintion of the deep reinforcement learning, some popular algorithms for example deep Q learning and variants, policy gradient methods and actor-critic methods for example A3C, DDPG, and PPO. Besides, it also includes the applications of those models.
  </div>
</div>


<div class="quarto-title-meta">

    
    <div>
    <div class="quarto-title-meta-heading">Published</div>
    <div class="quarto-title-meta-contents">
      <p class="date">2024-10-25</p>
    </div>
  </div>
  
    <div>
    <div class="quarto-title-meta-heading">Last modified</div>
    <div class="quarto-title-meta-contents">
      <p class="date-modified">2024-10-28</p>
    </div>
  </div>
    
  </div>
  


</header>


<p>In recent years, Deep Reinforcement Learning has emerged as one of the most promising areas within the broader field of Artificial Intelligence(AI). It combines two powerful tools: reinforcement learning(RL), where agents learn by interacting with their environment, and deep learning, where neural networks identify patterns from large amounts of data.</p>
<p>The Markov Decision Process provide the mathematical foundation for DRL, enabling agents to make intelligent decision in complex environment. Let defines some key concepts first, for more details of the MDP, please check the following <a href="https://jaz201107.github.io/posts/Basic/MDP.html">blog</a></p>
<section id="key-concepts-and-notations" class="level1">
<h1>Key Concepts and Notations</h1>
<ul>
<li><span class="math inline">\(S\)</span>: The set of all possible stats in the environment</li>
<li><span class="math inline">\(A\)</span>: The set of actions that agent can take</li>
<li><span class="math inline">\(R(s, a)\)</span>: The reward function, which gives the immediate reward received after taking action <span class="math inline">\(a\)</span> in state <span class="math inline">\(s\)</span></li>
<li><span class="math inline">\(v(s)\)</span>: The State-Value function of the state, while <span class="math inline">\(V(s)\)</span> is an estimator of the true state value function <span class="math inline">\(v(s)\)</span></li>
</ul>
<p><span class="math display">\[
V^{\pi}(s) = \mathbb{E}_{\pi}\left[ \sum_{t=0}^{\infty}\gamma^{t}R_{t+1} | S_{0} = s \right]
\]</span></p>
<ul>
<li><span class="math inline">\(q(s, a)\)</span>: The State-Action function of the state-action pairs, while <span class="math inline">\(Q(s, a)\)</span> is an estimator of the true state-action function(<span class="math inline">\(q(s, a)\)</span>) <span class="math display">\[
Q^{\pi}(s, a) = \mathbb{E}_{\pi}\left[ \sum_{t=0}^{\infty}\gamma^{t}R_{t+1} | S_{0} = s, A_{0}=a \right]
\]</span> The state value function and state action value function are related through the following euqation: <span class="math display">\[
V^{\pi}(s) = \mathbb{E}_{a\sim \pi}[Q^{\pi}(s.)]
\]</span></li>
<li><span class="math inline">\(\gamma\)</span>: The discount factor <span class="math inline">\((0 \leq \gamma \leq 1)\)</span>, which determines how much the agent values future reward compared to immediate ones.</li>
<li><span class="math inline">\(G_{t}\)</span>: The return, is the cumulative reward, defined as <span class="math display">\[
G_{t} = \sum_{k=0}^{\infty}\gamma^{k}R_{t + k + 1}
\]</span></li>
<li><span class="math inline">\(A(s, a)\)</span>: The advantage function of the state-action pairs, which tells use how much better or worse a specific action <span class="math inline">\(a\)</span> is coompared to the average acction the policy would take in state <span class="math inline">\(s\)</span>.</li>
</ul>
</section>
<section id="q-learning-and-variants" class="level1">
<h1>Q-Learning and Variants</h1>
<section id="classical-deepq-learning" class="level2">
<h2 class="anchored" data-anchor-id="classical-deepq-learning">Classical (Deep)Q-Learning</h2>
<p>The classic Q-learning finds the optimal state-action value function <span class="math inline">\(Q(s, a)\)</span> through the Bellman Equation. The Q-value update rule is: <span class="math display">\[
Q(s_{t}, a_{t}) \leftarrow  Q(s_{t}, a_{t}) + \alpha(R_{t + 1} + \gamma \underset{a'}{\max \ }Q(s_{t+1}, a') - Q(s_{t}, a_{t}))
\]</span> When we use the neural network as function approximator, we need define an loss function to update the parameters. The Loss function is: <span class="math display">\[
\mathcal{L}(\theta) = \mathbb{E}[(R_{t+1} + \gamma \underset{a'}{\max \ }Q(s_{t+1}, a'; \theta^{-}) - Q(s_{t}, a_{t}; \theta) )^{2}]
\]</span></p>
<p>The problem of classical Q-Learning is that it suffer from overestimation bias, where the <code>max</code> operator selects actions that appear optimal due to noisy or high Q-value. To release this problem, we can use Double Q-Learning, it defined as</p>
</section>
<section id="double-deep-q-learning" class="level2">
<h2 class="anchored" data-anchor-id="double-deep-q-learning">Double (Deep) Q-Learning</h2>
<p>Double Q-Learning reduces overestimation bias by maintaining two Q-tables(or two networks in deep learning settings). Each table is updated independently to decouple the action selection and value estimation processes. The update rule is: <span class="math display">\[
Q_{1}(s_{t}, a_{t}) \leftarrow Q_{1}(s_{t}, a_{t}) + \alpha(R_{t+1} + \gamma Q_{2}(s_{t + 1}, \underset{a'}{\operatorname{arg\max}\ }Q_{1}(s_{t+1}, a') ) - Q_{1}(s_{t}, a_{t}))
\]</span></p>
<p>The Loss Function for the Double Deep Q_Learning is that: <span class="math display">\[
\mathcal{L}(\theta)=\mathbb{E}[(R_{t+1} + \gamma Q(s_{t+1}, \underset{a'}{\operatorname{arg\max}\ }Q(s_{t+1}, a'; \theta);\theta^{-} )-Q(s_{t}, a_{t}; \theta))^{2}]
\]</span></p>
</section>
<section id="dueling-dqn" class="level2">
<h2 class="anchored" data-anchor-id="dueling-dqn">Dueling DQN</h2>
<p>The problem of the Basic DQN is that not all actions are equally relevant in every state, but DQN treats all state-action equally, to solve this problem, we can use Dueling DQN, which separates the Q-value into two components: * State-Value function <span class="math inline">\(V(s)\)</span>: measures the value of being in state <span class="math inline">\(s\)</span> * Advantage function <span class="math inline">\(A(s, a)\)</span>, which measures the relative importance of taking action <span class="math inline">\(a\)</span> in state <span class="math inline">\(s\)</span>.</p>
<p>The Q-value is them computed as: <span class="math display">\[
Q(s, a) = V(s) + A(s, a) - \underset{a'}{\max \ } A(s, a')
\]</span></p>
</section>
<section id="noisy-q-learning" class="level2">
<h2 class="anchored" data-anchor-id="noisy-q-learning">Noisy Q-Learning</h2>
<p>In som environments, the agents needs better exploration strategies to avoid getting suck in local optima. The Noisy-Q-Learning introduces parametric noise into the neural network’s parameters, allowing the agent to explore more efficitively</p>
</section>
<section id="soft-q-learning" class="level2">
<h2 class="anchored" data-anchor-id="soft-q-learning">Soft Q-Learning</h2>
<p>Soft Q-learning introduces an entropy term into the objective to encourage exploration. The agent seeks to maximize both the cumulative reawrd and the policy entropy, learning yo better exploration in uncertain environemnts</p>
<p>The Objective Function become: <span class="math display">\[
J(\pi) =\mathbb{E}\left[ \sum_{t}(R_{t} + \alpha \mathcal{H}(\pi(\cdot | s_{t}))) \right]
\]</span></p>
</section>
<section id="experience-replay-buffer" class="level2">
<h2 class="anchored" data-anchor-id="experience-replay-buffer">Experience Replay Buffer</h2>
</section>
<section id="section" class="level2">
<h2 class="anchored" data-anchor-id="section"></h2>
</section>
</section>
<section id="policy-based-algorithm" class="level1">
<h1>Policy Based Algorithm</h1>
<section id="reinforce" class="level2">
<h2 class="anchored" data-anchor-id="reinforce">REINFORCE</h2>
<p>REINFORCE is the most basic algorithm used in the reinforcement learning algorithms.</p>
</section>
<section id="actor-critic-methods" class="level2">
<h2 class="anchored" data-anchor-id="actor-critic-methods">Actor-Critic Methods</h2>
<section id="basic-actor-critic-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="basic-actor-critic-algorithm">Basic Actor-Critic Algorithm</h3>
</section>
<section id="advantage-actor-critic-algorithm" class="level3">
<h3 class="anchored" data-anchor-id="advantage-actor-critic-algorithm">Advantage Actor-Critic Algorithm</h3>
</section>
<section id="asyn-advantage-actor-critic-algorithm-a3d" class="level3">
<h3 class="anchored" data-anchor-id="asyn-advantage-actor-critic-algorithm-a3d">Asyn Advantage Actor-Critic Algorithm (A3D)</h3>
</section>
</section>
<section id="trust-region-policy-optimization" class="level2">
<h2 class="anchored" data-anchor-id="trust-region-policy-optimization">Trust Region Policy Optimization</h2>
</section>
<section id="proximal-policy-optimization" class="level2">
<h2 class="anchored" data-anchor-id="proximal-policy-optimization">Proximal Policy Optimization</h2>
<p>This is an simpller alternative to TRPO</p>
</section>
</section>
<section id="inverse-reinforcement-learning" class="level1">
<h1>Inverse Reinforcement Learning</h1>
</section>
<section id="meta-reinforcement-learning" class="level1">
<h1>Meta Reinforcement Learning</h1>
</section>
<section id="reinforcement-learning-and-inference" class="level1">
<h1>Reinforcement Learning and Inference</h1>
</section>
<section id="reinforcement-learning-with-sequence-models" class="level1">
<h1>Reinforcement Learning with Sequence Models</h1>
</section>
<section id="reference" class="level1">
<h1>Reference</h1>
<p>[1] <a href="https://spinningup.openai.com/en/latest/">OpenAI Spinning Up</a> [2] <a href="https://lilianweng.github.io/posts/2018-04-08-policy-gradient/">Lil’ Log Policy Gradient Algorithms</a> [3] <a href="https://rail.eecs.berkeley.edu/deeprlcourse/">UCB CS 285 Deep Reinforcement Learning 2023</a> [4] <a href="https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf">Andrew Barto and Richard S. Sutto: Reinforcement Learning an Introducntion</a></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const disableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'prefetch';
    }
  }
  const enableStylesheet = (stylesheets) => {
    for (let i=0; i < stylesheets.length; i++) {
      const stylesheet = stylesheets[i];
      stylesheet.rel = 'stylesheet';
    }
  }
  const manageTransitions = (selector, allowTransitions) => {
    const els = window.document.querySelectorAll(selector);
    for (let i=0; i < els.length; i++) {
      const el = els[i];
      if (allowTransitions) {
        el.classList.remove('notransition');
      } else {
        el.classList.add('notransition');
      }
    }
  }
  const toggleGiscusIfUsed = (isAlternate, darkModeDefault) => {
    const baseTheme = document.querySelector('#giscus-base-theme')?.value ?? 'light';
    const alternateTheme = document.querySelector('#giscus-alt-theme')?.value ?? 'dark';
    let newTheme = '';
    if(darkModeDefault) {
      newTheme = isAlternate ? baseTheme : alternateTheme;
    } else {
      newTheme = isAlternate ? alternateTheme : baseTheme;
    }
    const changeGiscusTheme = () => {
      // From: https://github.com/giscus/giscus/issues/336
      const sendMessage = (message) => {
        const iframe = document.querySelector('iframe.giscus-frame');
        if (!iframe) return;
        iframe.contentWindow.postMessage({ giscus: message }, 'https://giscus.app');
      }
      sendMessage({
        setConfig: {
          theme: newTheme
        }
      });
    }
    const isGiscussLoaded = window.document.querySelector('iframe.giscus-frame') !== null;
    if (isGiscussLoaded) {
      changeGiscusTheme();
    }
  }
  const toggleColorMode = (alternate) => {
    // Switch the stylesheets
    const alternateStylesheets = window.document.querySelectorAll('link.quarto-color-scheme.quarto-color-alternate');
    manageTransitions('#quarto-margin-sidebar .nav-link', false);
    if (alternate) {
      enableStylesheet(alternateStylesheets);
      for (const sheetNode of alternateStylesheets) {
        if (sheetNode.id === "quarto-bootstrap") {
          toggleBodyColorMode(sheetNode);
        }
      }
    } else {
      disableStylesheet(alternateStylesheets);
      toggleBodyColorPrimary();
    }
    manageTransitions('#quarto-margin-sidebar .nav-link', true);
    // Switch the toggles
    const toggles = window.document.querySelectorAll('.quarto-color-scheme-toggle');
    for (let i=0; i < toggles.length; i++) {
      const toggle = toggles[i];
      if (toggle) {
        if (alternate) {
          toggle.classList.add("alternate");     
        } else {
          toggle.classList.remove("alternate");
        }
      }
    }
    // Hack to workaround the fact that safari doesn't
    // properly recolor the scrollbar when toggling (#1455)
    if (navigator.userAgent.indexOf('Safari') > 0 && navigator.userAgent.indexOf('Chrome') == -1) {
      manageTransitions("body", false);
      window.scrollTo(0, 1);
      setTimeout(() => {
        window.scrollTo(0, 0);
        manageTransitions("body", true);
      }, 40);  
    }
  }
  const isFileUrl = () => { 
    return window.location.protocol === 'file:';
  }
  const hasAlternateSentinel = () => {  
    let styleSentinel = getColorSchemeSentinel();
    if (styleSentinel !== null) {
      return styleSentinel === "alternate";
    } else {
      return false;
    }
  }
  const setStyleSentinel = (alternate) => {
    const value = alternate ? "alternate" : "default";
    if (!isFileUrl()) {
      window.localStorage.setItem("quarto-color-scheme", value);
    } else {
      localAlternateSentinel = value;
    }
  }
  const getColorSchemeSentinel = () => {
    if (!isFileUrl()) {
      const storageValue = window.localStorage.getItem("quarto-color-scheme");
      return storageValue != null ? storageValue : localAlternateSentinel;
    } else {
      return localAlternateSentinel;
    }
  }
  const darkModeDefault = false;
  let localAlternateSentinel = darkModeDefault ? 'alternate' : 'default';
  // Dark / light mode switch
  window.quartoToggleColorScheme = () => {
    // Read the current dark / light value 
    let toAlternate = !hasAlternateSentinel();
    toggleColorMode(toAlternate);
    setStyleSentinel(toAlternate);
    toggleGiscusIfUsed(toAlternate, darkModeDefault);
  };
  // Ensure there is a toggle, if there isn't float one in the top right
  if (window.document.querySelector('.quarto-color-scheme-toggle') === null) {
    const a = window.document.createElement('a');
    a.classList.add('top-right');
    a.classList.add('quarto-color-scheme-toggle');
    a.href = "";
    a.onclick = function() { try { window.quartoToggleColorScheme(); } catch {} return false; };
    const i = window.document.createElement("i");
    i.classList.add('bi');
    a.appendChild(i);
    window.document.body.appendChild(a);
  }
  // Switch to dark mode if need be
  if (hasAlternateSentinel()) {
    toggleColorMode(true);
  } else {
    toggleColorMode(false);
  }
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
          // target, if specified
          link.setAttribute("target", "_blank");
          if (link.getAttribute("rel") === null) {
            link.setAttribute("rel", "noopener");
          }
          // default icon
          link.classList.add("external");
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>